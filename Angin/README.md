# ğŸŒ¬ï¸ Angin â€“ Emotional Support Voice Assistant

> *"Let the wind carry your worries away"*

**Angin** (Indonesian for "wind") is a mobile emotional support app that provides a safe, judgment-free space to express your feelings through voice. Speak your worries, and Angin listens, reflects, and gently guides you toward clarity.

---

## ğŸ¯ Overview

Angin acts like an emotional support "phone call" â€” a calm, empathetic AI companion available whenever life feels overwhelming. It's designed for moments when you need to talk but can't reach out to anyone, when your thoughts feel tangled, or when you just need someone to listen.

**Angin is NOT:**
- A crisis hotline
- A replacement for therapy
- Medical or diagnostic advice

**Angin IS:**
- A safe space to express emotions
- A tool for self-awareness and reflection
- A gentle guide through stress, anxiety, and overwhelm

---

## ğŸ¬ Live Demo

**Try Angin now:**

- **Mobile App (APK):** [https://expo.dev/accounts/marsela_engo/projects/Angin]
- **Backend API:** [https://angin-ai-production.up.railway.app]

**Note:** No login required. Install and start using immediately.

---


## ğŸ“‹ Submission Details

### Kiro Hackathon Submission

**Main Category:** Mobile AI App

**Bonus Category:** Best Use of Steering Documents

**Why this bonus category?**  
Angin demonstrates advanced use of Kiro's steering documents to enforce therapeutic behavior, safety constraints, and consistent tone across all AI responses. The `.kiro/steering/angin-therapy.md` file defines:
- Emotional support boundaries (not medical advice, not crisis intervention)
- Structured JSON output format with mood, urgency, and strategy fields
- Tone guidelines (warm, calm, short replies under 50 words)
- Safety rules for high-urgency situations

This steering document ensures every response follows evidence-based therapeutic practices while maintaining emotional safety, making it a core architectural component rather than just configuration.

---

## âœ¨ Features

- **ğŸ¤ Voice-First Interface** â€“ Speak naturally, no typing required
- **ğŸ§  Emotional Intelligence** â€“ AI-powered mood detection and analysis
- **ğŸ’¬ Conversational Therapy Agent** â€“ Structured emotional support using validated strategies
- **ğŸ”Š Natural TTS Responses** â€“ Warm, human-like voice feedback via ElevenLabs
- **ğŸ“Š Structured Insights** â€“ Mood, urgency, and strategy tracking for each conversation
- **ğŸ”’ Privacy-Focused** â€“ Conversations are processed in real-time, not stored permanently

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  React Native   â”‚  User speaks into the app
â”‚   (Expo App)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Audio (multipart/form-data)
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI Server â”‚
â”‚                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚    STT    â”‚  â”‚  OpenAI Whisper (gpt-4o-transcribe)
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚
â”‚        â”‚        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Therapy  â”‚  â”‚  GPT-4o-mini with structured JSON output
â”‚  â”‚   Agent   â”‚  â”‚  (mood, urgency, strategy, response)
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚
â”‚        â”‚        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚    TTS    â”‚  â”‚  ElevenLabs text-to-speech
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Audio (audio/mpeg)
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User hears    â”‚
â”‚    response     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¤– How Kiro Was Used

Kiro AI was instrumental in accelerating Angin's development from concept to working prototype. Here's how we leveraged Kiro's key features:

### Vibe Coding

Kiro served as my primary development partner throughout the project. I used conversational prompts to:
- Scaffold FastAPI endpoints with proper Pydantic validation
- Design JSON response schemas for the therapy agent
- Build React Native screens with audio recording and playback
- Iterate rapidly by sending error messages and receiving targeted fixes
- Refactor code for performance (e.g., reducing system prompt tokens from ~300 to ~200)

The vibe coding approach allowed me to focus on therapeutic quality and user experience while Kiro handled implementation details.

### Spec-Driven Development

I created a structured specification for the Angin therapy agent that defined:
- Output schema: `mood`, `urgency`, `strategy`, `response`, `next_action`
- Therapeutic strategies: reflect, clarify, grounding, reframe, close
- Safety constraints: urgency detection, crisis handling, professional help referrals

Kiro used this spec to generate stable, predictable agent logic with enforced JSON output mode. When requirements changed, I updated the spec and Kiro regenerated the implementation consistently.

### Steering Documents

The `.kiro/steering/angin-therapy.md` steering document defines the therapy agent's core behavior:
- **Purpose:** Emotional support, explicitly NOT crisis intervention or medical advice
- **Tone:** Warm, calm, human, never robotic or overly cheerful
- **Response format:** 1-3 short sentences, under 50 words, no emojis or markdown
- **Safety rules:** High urgency detection with gentle validation, avoid prescriptive crisis instructions

This steering file is automatically included in Kiro's context, ensuring all generated code follows therapeutic best practices. It acts as a "constitution" for the AI's behavior, making the system reliable and safe.

### Hooks

**Current Usage:** Minimal in this version.

**Planned Usage:** In future iterations, Kiro hooks will:
- Auto-regenerate agent code when the therapy spec is updated
- Run test suites automatically after endpoint changes
- Update documentation when API contracts change
- Trigger linting and validation on file save

### Model Context Protocol (MCP)

**Status:** Not used in this version.

**Future Consideration:** MCP could enable integration with external mental health resources, crisis databases, or therapist referral systems.

---

## ğŸ› ï¸ Tech Stack

### Frontend
- **React Native** â€“ Cross-platform mobile framework
- **Expo** â€“ Development platform and tooling
- **expo-av** â€“ Audio recording
- **expo-speech** â€“ Text-to-speech playback
- **TypeScript** â€“ Type-safe development

### Backend
- **FastAPI** â€“ High-performance Python web framework
- **OpenAI API**
  - `gpt-4o-transcribe` â€“ Speech-to-text
  - `gpt-4o-mini` â€“ Conversational therapy agent with JSON mode
- **ElevenLabs API** â€“ Natural text-to-speech
- **Pydantic** â€“ Request/response validation

### AI/ML
- **Structured JSON Output** â€“ Enforced response format for reliability
- **Conversation History** â€“ Context-aware multi-turn conversations
- **Therapy Strategies** â€“ Reflection, validation, grounding, reframing, closure

---

## ğŸ“ Project Structure

```
Angin/
â”œâ”€â”€ app/                      # React Native screens (Expo Router)
â”‚   â”œâ”€â”€ (tabs)/              # Tab navigation screens
â”‚   â”œâ”€â”€ splash.tsx           # Welcome/splash screen
â”‚   â”œâ”€â”€ dial.tsx             # Phone dial interface
â”‚   â”œâ”€â”€ call.tsx             # Active call screen
â”‚   â”œâ”€â”€ index.tsx            # Home screen
â”‚   â””â”€â”€ _layout.tsx          # Root layout
â”œâ”€â”€ backend/                 # FastAPI server
â”‚   â”œâ”€â”€ main.py              # API endpoints and business logic
â”‚   â”œâ”€â”€ requirements.txt     # Python dependencies
â”‚   â””â”€â”€ .env                 # Environment variables (API keys)
â”œâ”€â”€ components/              # Reusable React components
â”‚   â”œâ”€â”€ ui/                  # UI component library
â”‚   â””â”€â”€ themed-*.tsx         # Theme-aware components
â”œâ”€â”€ constants/               # App constants and theme
â”œâ”€â”€ hooks/                   # Custom React hooks
â”œâ”€â”€ scripts/                 # Testing and utility scripts
â”‚   â”œâ”€â”€ test_angin_turn.py   # Test therapy agent endpoint
â”‚   â””â”€â”€ test_angin_call.py   # Test full audio pipeline
â”œâ”€â”€ assets/                  # Images, icons, fonts
â”œâ”€â”€ .kiro/                   # Kiro AI steering rules
â”‚   â””â”€â”€ steering/
â”‚       â””â”€â”€ angin-therapy.md # Therapy agent behavior guidelines
â”œâ”€â”€ package.json             # Node.js dependencies
â”œâ”€â”€ app.json                 # Expo configuration
â””â”€â”€ README.md                # This file
```

---

## ğŸ”Œ API Documentation

### Core Endpoints

#### `POST /angin/call`
**Full audio-to-audio therapy flow**

**Request:**
- `audio` (file): Audio recording (mp3, wav, m4a, etc.)
- `summary` (optional): Running conversation summary
- `history` (optional): JSON string of previous messages

**Response:**
- `audio/mpeg` â€“ TTS audio of the therapy response
- Headers:
  - `X-Transcript`: User's transcribed text
  - `X-Mood`: Detected mood (anxious, sad, overwhelmed, numb, angry, mixed)
  - `X-Urgency`: Urgency level (low, medium, high)
  - `X-Strategy`: Applied strategy (reflect, clarify, grounding, reframe, close)
  - `X-Response-Text`: Text version of the response
  - `X-Next-Action`: Suggested next action (tts_output, ask_more, end)

---

#### `POST /angin/call-json`
**Same flow, returns JSON instead of audio**

**Request:** Same as `/angin/call`

**Response (JSON):**
```json
{
  "transcript": "I've been feeling really anxious about work...",
  "mood": "anxious",
  "urgency": "medium",
  "strategy": "reflect",
  "response_text": "That sounds really hard. When work feels overwhelming, it's tough to find peace. What's weighing on you most?",
  "next_action": "ask_more"
}
```

---

#### `POST /angin/turn`
**Therapy agent only (no audio processing)**

**Request (JSON):**
```json
{
  "summary": "User discussing work stress and sleep issues",
  "history": [
    {"role": "user", "content": "I can't stop thinking about my deadline"},
    {"role": "assistant", "content": "That sounds stressful. Tell me more."}
  ]
}
```

**Response (JSON):**
```json
{
  "mood": "anxious",
  "urgency": "medium",
  "strategy": "grounding",
  "response": "It's okay to feel this way. Let's take a breath together. What's one small thing you can control right now?",
  "next_action": "ask_more"
}
```

---

### Legacy Endpoints

- `POST /analyze` â€“ Audio transcription + old analysis format
- `GET /speak?text=...` â€“ Direct TTS (text to audio)
- `GET /health` â€“ Health check

---
**Note:** No login required. Install and start using immediately.

## ğŸš€ Setup Instructions

### Prerequisites

- **Node.js** (v18+)
- **Python** (3.9+)
- **Expo CLI** (`npm install -g expo-cli`)
- **API Keys:**
  - OpenAI API key
  - ElevenLabs API key

### Backend Setup

1. **Navigate to backend directory:**
   ```bash
   cd Angin/backend
   ```

2. **Create virtual environment:**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment variables:**
   Create `.env` file:
   ```env
   OPENAI_API_KEY=your_openai_key_here
   ELEVENLABS_API_KEY=your_elevenlabs_key_here
   ELEVENLABS_VOICE_ID=your_voice_id_here
   ```

5. **Run the server:**
   ```bash
   uvicorn main:app --reload --host 0.0.0.0 --port 8000
   ```

   Server will be available at `http://localhost:8000`

### Frontend Setup

1. **Navigate to project root:**
   ```bash
   cd Angin
   ```

2. **Install dependencies:**
   ```bash
   npm install
   ```

3. **Update API endpoint:**
   Edit your app code to point to your backend URL (e.g., `http://192.168.x.x:8000` for local network testing)

4. **Start Expo development server:**
   ```bash
   npm start
   ```

5. **Run on device/simulator:**
   - Press `i` for iOS simulator
   - Press `a` for Android emulator
   - Scan QR code with Expo Go app for physical device

---

## ğŸ§ª Testing

### Test Therapy Agent
```bash
python scripts/test_angin_turn.py
```

### Test Full Audio Pipeline
```bash
# Requires a test audio file
python scripts/test_angin_call.py
```

### Manual API Testing
```bash
# Health check
curl http://localhost:8000/health

# Test TTS
curl "http://localhost:8000/speak?text=Hello%20world" --output test.mp3

# Test therapy agent
curl -X POST http://localhost:8000/angin/turn \
  -H "Content-Type: application/json" \
  -d '{
    "history": [
      {"role": "user", "content": "I feel overwhelmed"}
    ]
  }'
```

---

## âš ï¸ Safety & Limitations

### What Angin Does
- Provides emotional support and validation
- Helps identify feelings and patterns
- Offers gentle guidance and reflection
- Uses evidence-based conversational strategies

### What Angin Does NOT Do
- **Not a crisis service** â€“ If you're in crisis, contact emergency services or a crisis hotline
- **Not medical advice** â€“ Does not diagnose or treat mental health conditions
- **Not a therapist** â€“ Cannot replace professional mental health care
- **Not for emergencies** â€“ For self-harm or suicidal thoughts, seek immediate professional help

### Crisis Resources
- **US:** National Suicide Prevention Lifeline: 988
- **International:** Find resources at [findahelpline.com](https://findahelpline.com)

---

## ğŸ” Privacy

- Audio is processed in real-time and not permanently stored on servers
- Conversations are sent to OpenAI and ElevenLabs APIs (subject to their privacy policies)
- No user accounts or persistent data storage in current version
- For production use, implement proper data handling and privacy controls

---

## ğŸ—ºï¸ Roadmap

- [ ] Conversation history and mood timeline
- [ ] Silence-based auto-stop for recordings
- [ ] Interruptible TTS playback
- [ ] Offline mode with local models
- [ ] Multi-language support
- [ ] Integration with mental health resources
- [ ] User accounts and encrypted storage

---

## ğŸ”“ Authentication Notes

**No login required.** Angin is designed for immediate access:
- No user accounts or registration
- No authentication barriers
- Install and start using immediately
- Judges can test the app without any setup

This design choice prioritizes accessibility â€” when someone needs emotional support, they shouldn't have to create an account first.

---

## ğŸ“‚ Folder Structure Compliance

### Kiro-Specific Directories

The `.kiro/` directory at the project root contains Kiro AI configuration:

```
.kiro/
â””â”€â”€ steering/
    â””â”€â”€ angin-therapy.md    # Therapy agent behavior guidelines
```

**Note:** The `/hooks` directory in the project root contains **React hooks** (custom React logic), which are separate from **Kiro hooks** (agent automation). Kiro hooks would be stored in `.kiro/hooks/` when implemented.

### Project Organization

- **Frontend code:** `/app`, `/components`, `/constants`
- **Backend code:** `/backend`
- **Documentation:** `/docs` (ARCHITECTURE.md, DEVPOST_SUMMARY.md)
- **Testing scripts:** `/scripts`
- **Kiro configuration:** `/.kiro`

---

## ğŸ“„ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¥ Contact

**Project Maintainer:** Intan Marsela  
**Email:** Marsela.code@gmail.com  
**GitHub:** [github.com/Intanmarsela/Angin-ai](https://github.com/Intanmarsela/Angin-ai)

---

## ğŸ™ Acknowledgments

- **OpenAI** â€“ GPT-4o models for transcription and conversation
- **ElevenLabs** â€“ Natural text-to-speech voices
- **Expo** â€“ React Native development platform
- **FastAPI** â€“ Modern Python web framework

---

**Built with â¤ï¸ for mental wellness and emotional support**

*Remember: Self-awareness is the foundation of growth. Naming your problem is already half the solution.*
